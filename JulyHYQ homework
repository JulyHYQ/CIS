def the_vec_func(self, files_in):
        from sklearn.feature_extraction.text import CountVectorizer
        from sklearn import preprocessing
        
        the_vec = CountVectorizer()
        cnt_vec = pd.DataFrame(the_vec.fit_transform(files_in.body).toarray())
        cnt_vec.columns = the_vec.get_feature_names()
        
        lab_enc = preprocessing.LabelEncoder()
        the_labels = pd.DataFrame(lab_enc.fit_transform(files_in.label))
        
        return the_vec, lab_enc, cnt_vec, the_labels

    def pca_step(self, data_in, num_comp):
        from sklearn.decomposition import PCA
        my_vec_model = PCA(n_components=num_comp)
        my_vec_model.fit(data_in)
        my_vec_pca = my_vec_model.transform(data_in)
        
        print ("Variance Explained: " + str(sum(my_vec_model.explained_variance_ratio_)))
        
        return my_vec_pca
    
    def grid_search_func(self, param_grid, the_mode_in, the_vec_in, the_lab_in):
        from sklearn.model_selection import GridSearchCV
        
        grid_search = GridSearchCV(the_mode_in, param_grid=param_grid, cv=5)
        best_model = grid_search.fit(the_vec_in, the_lab_in)
        
        max_score = grid_search.best_score_
        best_params = grid_search.best_params_
        
        return best_model, max_score, best_params
    
    def full_train(self, the_model, gridsearch_model_in, my_vec_in, labels_in):
        the_model.set_params(**gridsearch_model_in.best_params_)
        the_model.fit(my_vec_in, labels_in)
        feature_imp = the_model.feature_importances_
        
        return the_model, feature_imp
    
    def predict(self, the_model, vec_mod, label_dec, path_in):
        first = input（val）
        print （val）
        test_data = vec_mod.transform([first])
        the_prediction = label_dec.inverse_transform(the_model.predict(test_data)[0])
        print (the_model.predict_proba(test_data)[0])
        score = max(the_model.predict_proba(test_data)[0])
        
        return the_prediction, score5
